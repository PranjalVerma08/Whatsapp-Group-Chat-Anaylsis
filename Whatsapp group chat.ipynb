{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whatsapp Group Chat Analysis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the group chat file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=pd.read_csv(r\"C:\\Users\\hp\\Downloads\\WhatsApp Chat with Brahma 2019-23.txt\", delimiter = \"\\t\", header = None, names = ['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[['datetime_str', 'text_2']] = a[\"text\"].str.split(\" - \", 1, expand=True)\n",
    "a[\"datetime\"] = pd.to_datetime(a[\"datetime_str\"],\n",
    "                               format=\"%d/%m/%Y, %I:%M %p\",\n",
    "                               errors='coerce')\n",
    "a[['sender', 'text_message']] = a['text_2'].str.split(': ', 1, expand=True)\n",
    "a['first_name'] = a['sender'].str.split(' ', expand=True)[0]\n",
    "a['last_name'] = a['sender'].str.split(' ', 1, expand=True)[1]\n",
    "a['sender'] = a['first_name'].where(\n",
    "    a['last_name'].isnull(), a['first_name'] + ' ' + a['last_name'].str[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['date_col'] = pd.to_datetime(a['datetime_str'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['Date'] = a['date_col'].dt.date\n",
    "a['Time'] = a['date_col'].dt.strftime('%H:%M')\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.drop(\n",
    "    ['text', 'datetime_str', 'text_2', 'datetime', 'first_name', 'last_name'],\n",
    "    axis=1,\n",
    "    inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heatmap for Hour of Day v/s Day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['day_of_week'] = a['date_col'].dt.dayofweek + 1\n",
    "a['hour_of_day'] = a['date_col'].dt.hour\n",
    "\n",
    "# Create new Dataframe containing data counts\n",
    "heatmap_data = a.groupby(['day_of_week', 'hour_of_day']).size()\n",
    "heatmap_data = heatmap_data.unstack()\n",
    "\n",
    "# Create heatmap\n",
    "plt.pcolor(heatmap_data, cmap='Reds')\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Day of Week\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart for sender message count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sender_count_series = a.groupby(['sender']).size().sort_values(ascending=False).head(20)\n",
    "\n",
    "# Create sender counts series as a DataFrame\n",
    "sender_count_df = pd.DataFrame(sender_count_series)\n",
    "\n",
    "# Reset index in order to name columns correctly\n",
    "sender_count_df = sender_count_df.reset_index()\n",
    "sender_count_df.columns = ['sender', 'count']\n",
    "\n",
    "# Plot bar chart with sender message counts\n",
    "plt.figure(figsize=(15, 5))\n",
    "New_Colors = ['red','green','blue','purple','orange','maroon','black','cyan','violet','navy']\n",
    "plt.bar(sender_count_df['sender'], sender_count_df['count'], color = New_Colors )\n",
    "plt.xlabel(\"Sender\")\n",
    "plt.ylabel(\"Message Count\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_value_counts = a['sender'].value_counts() \n",
    "top_10_author_value_counts = author_value_counts.head(10) \n",
    "top_10_author_value_counts.plot.barh(color = New_Colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_author_value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manipulation : Replacing null message and spamming blank space message with 'Jai Brahma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a['text_message'] = a['text_message'].replace(np.nan, 'Jai Brahma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most used Emoji's "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis = pd.DataFrame(columns=['sender','emoji','date_col'])\n",
    "\n",
    "# Loop through all messages in the DataFrame\n",
    "for sender, message, date_col in zip(a.sender, a.text_message, a.date_col):\n",
    "\n",
    "  # Split out each word in each message\n",
    "  message_split = list(message)\n",
    " \n",
    "  # Loop through each word in split message\n",
    "  for character in message_split:\n",
    " \n",
    "    # If the word is an emoji\n",
    "    if character in emoji.UNICODE_EMOJI and character != \"\\U0001f3fc\":\n",
    " \n",
    "      # Add each emoji to the DataFrame\n",
    "      emojis = emojis.append({'sender' : sender, 'emoji' : character, 'date_col' : date_col}, ignore_index=True)\n",
    "\n",
    "# Display top n most popular emojis\n",
    "emojis.groupby(['emoji']).size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Wise Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_count(text):\n",
    "\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X', text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "\n",
    "    return emoji_list\n",
    "\n",
    "\n",
    "total_messages = a.shape[0]\n",
    "media_messages = a[a['text_message'] == '<Media omitted>'].shape[0]\n",
    "a[\"emoji\"] = a[\"text_message\"].apply(split_count)\n",
    "emojis = sum(a['emoji'].str.len())\n",
    "URLPATTERN = r'(https?://\\S+)'\n",
    "a['urlcount'] = a.text_message.apply(\n",
    "    lambda x: re.findall(URLPATTERN, x)).str.len()\n",
    "links = np.sum(a.urlcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total messages in group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total media messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total emojis used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total links sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Omitting Media messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_messages_df = a[a['text_message'] == '<Media omitted>']\n",
    "messages_df = a.drop(media_messages_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df['Letter_Count'] = messages_df['text_message'].apply(\n",
    "    lambda s: len(s))\n",
    "messages_df['Word_Count'] = messages_df['text_message'].apply(\n",
    "    lambda s: len(s.split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sender wise Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = messages_df.sender.unique()\n",
    "\n",
    "for i in range(len(l)):\n",
    "    # Filtering out messages of particular user\n",
    "    req_df = messages_df[messages_df[\"sender\"] == l[i]]\n",
    "    # req_df will contain messages of only one particular user\n",
    "    print(f'Stats of {l[i]} -')\n",
    "    # shape will print number of rows which indirectly means the number of messages\n",
    "    print('Messages Sent', req_df.shape[0])\n",
    "    #Word_Count contains of total words in one message. Sum of all words/ Total Messages will yield words per message\n",
    "    words_per_message = (np.sum(req_df['Word_Count'])) / req_df.shape[0]\n",
    "    print('Words per message', words_per_message)\n",
    "    #media conists of media messages\n",
    "    media = media_messages_df[media_messages_df['sender'] == l[i]].shape[0]\n",
    "    print('Media Messages Sent', media)\n",
    "    # emojis conists of total emojis\n",
    "    emojis = sum(req_df['emoji'].str.len())\n",
    "    print('Emojis Sent', emojis)\n",
    "    #links consist of total links\n",
    "    links = sum(req_df[\"urlcount\"])\n",
    "    print('Links Sent', links)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#emojis.groupby(['emoji']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total count of words in all messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(review for review in messages_df.text_message)\n",
    "print (\"There are {} words in all the messages.\".format(len(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud of most used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(background_color=\"white\").generate(text)\n",
    "plt.figure( figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most happening day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = messages_df.groupby(\"Date\").sum()\n",
    "date_df.reset_index(inplace=True)\n",
    "date_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df['Date'].value_counts().head(10).plot.barh(color = New_Colors)\n",
    "plt.xlabel('Number of Messages')\n",
    "plt.ylabel('Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most happening time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df['Time'].value_counts().head(10).plot.barh(color = New_Colors)\n",
    "plt.xlabel('Number of messages')\n",
    "plt.ylabel('Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of words used by top 10 Senders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word_count_grouped_by_author = messages_df[['sender', 'Word_Count'\n",
    "                                                  ]].groupby('sender').sum()\n",
    "sorted_total_word_count_grouped_by_author = total_word_count_grouped_by_author.sort_values(\n",
    "    'Word_Count', ascending=False)\n",
    "top_10_sorted_total_word_count_grouped_by_author = sorted_total_word_count_grouped_by_author.head(\n",
    "    10)\n",
    "top_10_sorted_total_word_count_grouped_by_author.plot.barh(color='navy')\n",
    "plt.xlabel('Number of Words')\n",
    "plt.ylabel('sender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#req_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top words used by all group members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = messages_df.sender.unique()\n",
    "for i in range(len(l)):\n",
    "    dummy_df = messages_df[messages_df['sender'] == l[i]]\n",
    "    text = \" \".join(review for review in dummy_df.text_message)\n",
    "    stopwords = set(STOPWORDS)\n",
    "    stopwords.update([\"kya\", \"message\", \"deleted\", \"hai\", \"tha\", \"ki\"])\n",
    "    \n",
    "    print('Sender', l[i])\n",
    "    \n",
    "    wordcloud = WordCloud(background_color=\"white\").generate(text)\n",
    "   \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
